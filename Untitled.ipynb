{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42f1fd5-e09b-49f3-bd82-969399b6c74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "arr = [1,2,3,4]\n",
    "arr1 = torch.tensor(arr)\n",
    "print(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb8a25a5-50ae-487f-90e5-894fc3427658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sents(sents, pad_token):\n",
    "    \"\"\" Pad list of sentences according to the longest sentence in the batch.\n",
    "        The paddings should be at the end of each sentence.\n",
    "    @param sents (list[list[str]]): list of sentences, where each sentence\n",
    "                                    is represented as a list of words\n",
    "    @param pad_token (str): padding token\n",
    "    @returns sents_padded (list[list[str]]): list of sentences where sentences shorter\n",
    "        than the max length sentence are padded out with the pad_token, such that\n",
    "        each sentences in the batch now has equal length.\n",
    "    \"\"\"\n",
    "    sents_padded = []\n",
    "    \n",
    "    ### YOUR CODE HERE (~6 Lines)\n",
    "    max_len = 0\n",
    "    # for sent in sents:\n",
    "    #     if max_len<len(sent): max_len = len(sent)\n",
    "    max_len = max([len(sent) for sent in sents])\n",
    "    for sent in sents:\n",
    "        temp_max_len = max_len\n",
    "        temp_sent_padded = sent[:] #deep copy\n",
    "        while temp_max_len >len(sent):\n",
    "            temp_sent_padded+= [pad_token]\n",
    "            temp_max_len-=1\n",
    "        sents_padded.append(temp_sent_padded)\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return sents_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32809b2b-743a-463a-9b56-b360c5b32223",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [[1,2],[4,7,22,19],[21,26,33]]\n",
    "pad_token = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc5ebc92-2960-4be3-96c0-652dc85e6305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 0, 0], [4, 7, 22, 19], [21, 26, 33, 0]]\n"
     ]
    }
   ],
   "source": [
    "sents_padded = pad_sents(sents,pad_token)\n",
    "print(sents_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96267fb2-9533-4ebc-8893-559b73188cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "arr = torch.tensor([[1,2],[1,4]])\n",
    "print(arr[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01cc176d-0299-4d07-8dfe-77ba82989570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0ab0181-4c8a-432d-962f-e9c11072220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "cnn = nn.Conv1d(5,5,2,padding = 0)\n",
    "x = torch.rand(4,5,5)\n",
    "x = cnn(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e9c2a709-abef-44fa-a1d3-4f857f2dd211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanio/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1003.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "m = nn.Conv1d(16, 16, 2, padding = 'same')\n",
    "input = torch.randn(20, 16, 50)\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4512cec9-569e-4ec8-a602-959155c35798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.2686, -0.0887, -1.3013, -1.7183,  0.3886,  0.7967, -0.1148,\n",
      "           0.0402,  1.1946,  2.1518],\n",
      "         [ 1.3692,  0.0368, -1.5595, -0.2403,  1.5011,  0.3989,  0.7902,\n",
      "           0.9096, -0.7245, -1.7963],\n",
      "         [-0.1454,  0.2198,  0.2191, -0.7419,  0.9873,  0.1301,  1.4626,\n",
      "          -0.1151, -1.6673,  1.3263]],\n",
      "\n",
      "        [[-1.0817,  0.5678,  0.0279, -0.2206, -1.6152,  0.6848, -1.2034,\n",
      "          -1.9517, -0.3355, -1.3131],\n",
      "         [-0.2895, -0.1561,  0.2829, -0.3124, -0.3977, -0.3395, -0.3205,\n",
      "           0.4811,  0.4331,  1.1488],\n",
      "         [-0.5331,  1.7968,  0.5568, -1.3134, -1.7701,  0.1263, -3.4596,\n",
      "          -0.5030,  2.0480,  0.9363]],\n",
      "\n",
      "        [[-0.0680,  1.1995, -0.6107,  1.3084, -0.0228,  1.2665,  0.4886,\n",
      "           0.5372,  0.2456,  0.2854],\n",
      "         [-0.1632, -1.0990, -0.1988,  0.8380,  0.8038, -0.7625, -0.1568,\n",
      "          -0.6922, -1.1111, -0.0391],\n",
      "         [ 0.5037, -1.0974,  0.6583,  1.4203,  0.6227,  1.7451,  0.8624,\n",
      "          -0.2590, -0.1598,  0.6040]],\n",
      "\n",
      "        [[-0.5094, -0.3159,  0.6355, -2.4146,  0.6272,  0.9812,  0.3207,\n",
      "           1.1484,  1.7498,  0.9246],\n",
      "         [-0.2924, -0.3426,  1.3722, -0.3695,  0.2135, -0.9753,  1.9541,\n",
      "           1.5609, -1.2200, -0.7169],\n",
      "         [ 1.1594, -0.9415, -0.3184, -0.2297,  0.3902, -0.3682, -1.8604,\n",
      "          -0.1092,  1.2293,  0.5769]],\n",
      "\n",
      "        [[ 0.9618, -0.7747,  0.5157,  2.3522,  1.1151,  0.7907,  1.4929,\n",
      "          -0.6046, -0.4945,  0.5058],\n",
      "         [-1.4835, -0.1901,  0.4755,  0.7719,  0.4883,  0.9949,  0.7748,\n",
      "          -0.1335,  1.4413, -1.3783],\n",
      "         [ 1.0161,  0.0835,  0.6394, -0.1762, -0.2369,  0.1834, -0.1639,\n",
      "           2.4498,  0.4648,  1.8302]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "start (12) + length (1) exceeds dimension size (12).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m pack_padded_sequence(\u001b[38;5;28minput\u001b[39m,[\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m output, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m output \u001b[38;5;241m=\u001b[39m pad_packed_sequence(output)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:815\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    812\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    817\u001b[0m output \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    818\u001b[0m hidden \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: start (12) + length (1) exceeds dimension size (12)."
     ]
    }
   ],
   "source": [
    "rnn = nn.LSTM(10, 20, bias = True, bidirectional = True)\n",
    "input = torch.randn(5, 3, 10)\n",
    "print(input)\n",
    "input = pack_padded_sequence(input,[6,4,3])\n",
    "output, (hn, cn) = rnn(input)\n",
    "output = pad_packed_sequence(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "091f13f6-c795-45e2-8138-4ddaa0bf5ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 40])\n",
      "torch.Size([2, 3, 20]) torch.Size([2, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "print(output.size())\n",
    "print(hn.size(),cn.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7ea0fa89-828b-44ff-be32-3d243d6e0222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "arr1 = torch.tensor([1])\n",
    "arr2 = torch.tensor([2])\n",
    "arr3 = torch.tensor([3])\n",
    "arr.append(arr1)\n",
    "arr.append(arr2)\n",
    "arr.append(arr3)\n",
    "arr = torch.stack(arr)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa8c452-c3ba-4f15-86f5-64a0dd495648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
